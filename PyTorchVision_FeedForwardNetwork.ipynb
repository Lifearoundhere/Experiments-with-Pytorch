{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchVision_FeedForwardNetwork.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lifearoundhere/Experiments-with-Pytorch/blob/master/PyTorchVision_FeedForwardNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55aKbuEE97pb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "88dfd01d-008b-4298-e82d-cdfd30c9bc3e"
      },
      "source": [
        "pip install torchvision matplotlib\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9a8KNEcDL7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IQ-pTsZD37r",
        "colab_type": "text"
      },
      "source": [
        "* Using torchs inbuild data (mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrOKjr19ajWA",
        "colab_type": "text"
      },
      "source": [
        "### Neural Network Input ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc50BxVBEIGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c5dba394-ae52-4301-e521-a80d6353c88c"
      },
      "source": [
        "train = datasets.MNIST(\"\", train=True, download=True,\n",
        "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test = datasets.MNIST(\"\", train=False, download=True,\n",
        "                      transform = transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27829968.31it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 441712.85it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7191350.44it/s]                            \n",
            "8192it [00:00, 179303.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEbDnQLXET_P",
        "colab_type": "text"
      },
      "source": [
        "* Test data should normally always be out of sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNlJDnwXFabU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZgcwDJSF5Ce",
        "colab_type": "text"
      },
      "source": [
        "*   batch is needed due to dataset size\n",
        "*   Go for the biggest batch size you can get away with to help with training times\n",
        "*   shuffle helps with generalisation (obfuscate overfit)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPm8J-g3ITDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "cc968b65-cb37-43e7-ebb9-a37d38f97e66"
      },
      "source": [
        "for data in trainset:\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 5, 5, 8, 9, 3, 8, 4, 6, 0])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfVq-0BdIn9Y",
        "colab_type": "text"
      },
      "source": [
        "* get first sample to review tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1FhhjQrI8-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e1b2ee6-2b24-4713-994f-8b8c40c02849"
      },
      "source": [
        "x, y = data[0][0], data[1][0]\n",
        "print( y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjN8LNSGKKAz",
        "colab_type": "text"
      },
      "source": [
        "* x is the image tensor, y is the result tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kNluDaFKSPD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "de3128ba-1cb3-48fa-b588-48d0c42fd0de"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(x.shape)\n",
        "plt.imshow(x.view(28,28))\n",
        "plt.show() "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADSf0f7RlPiIGjwbQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FSVTVGHM-I_",
        "colab_type": "text"
      },
      "source": [
        "* the Tensor delivers a three-dimensional object however and the image has only two. This need to be accounted for e.g\n",
        "```\n",
        "view(28,28)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGzb1uulPi5c",
        "colab_type": "text"
      },
      "source": [
        "### Checking for data balence ### "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMvmPWN5N_CD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "276e54d2-75b4-40f5-b87c-d710a3fc8ac2"
      },
      "source": [
        "total = 0\n",
        "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0,}\n",
        "\n",
        "for data in trainset:\n",
        "  xs, ys = data\n",
        "  for y in ys:\n",
        "    counter_dict[int(y)] += 1\n",
        "    total += 1\n",
        "\n",
        "print(counter_dict)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xYwAP_0PzzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "075a5946-c3a3-41d9-ed94-adfc57bf5491"
      },
      "source": [
        "for i in counter_dict:\n",
        "    print(f\"{i}: {counter_dict[i]/total*100}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 9.871666666666666\n",
            "1: 11.236666666666666\n",
            "2: 9.93\n",
            "3: 10.218333333333334\n",
            "4: 9.736666666666666\n",
            "5: 9.035\n",
            "6: 9.863333333333333\n",
            "7: 10.441666666666666\n",
            "8: 9.751666666666667\n",
            "9: 9.915000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN1aG9UlQbdh",
        "colab_type": "text"
      },
      "source": [
        "* The percentage distribution of the images above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMzX9Usba2FB",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JygNgkfa_Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84YTFdAvbkuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cd6db73b-8cc5-4f24-80d5-9e575110b408"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 64)\n",
        "    self.fc2 = nn.Linear(64, 64)\n",
        "    self.fc3 = nn.Linear(64, 64)\n",
        "    self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    return F.log_softmax(x, dim = 1)\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j54r9KLUb2DA",
        "colab_type": "text"
      },
      "source": [
        "```__init__```\n",
        "* When you initialise nn you inherit the method &  except the initialise method (```__init__```) \n",
        "* so you need to run initialise method if you need to ```super().__init__``` \n",
        "\n",
        "```fc1```\n",
        "\n",
        "* input is 784 because it the *flattened image* 28 x 28 = 784\n",
        "* output is 64 just because\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLzXYvUxguB7",
        "colab_type": "text"
      },
      "source": [
        "```fc4```\n",
        "* output is 10 because our data/images is the numbers 0 - 9\n",
        "\n",
        "```forward```\n",
        "* defines how our data will feed through the network\n",
        "\n",
        "```F.relu```\n",
        "* the activation function\n",
        "* This is if the neuron is firing or not (its a sigmoid)\n",
        "\n",
        "```F.log_softmax```\n",
        "* this returns the prob distbution etc [0, 0.22, 0.88]\n",
        "* dim is dimention (its like axis's) \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hoe10O9kMkX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e84c6a8a-7b99-4529-b9e6-b81a9fcc3740"
      },
      "source": [
        "X = torch.rand((28,28))\n",
        "X = X.view(-1, 28*28)\n",
        "output = net(X)\n",
        "print(output)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.2205, -2.2528, -2.4362, -2.3762, -2.3739, -2.3416, -2.2573, -2.3585,\n",
            "         -2.1956, -2.2427]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH1b4DzPlR9l",
        "colab_type": "text"
      },
      "source": [
        "* Above is an example of inputting and outputting on of the nn\n",
        "* returns an array of probabilities "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GycAuK1AmcSm",
        "colab_type": "text"
      },
      "source": [
        "### Training the Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54wsY72ynrQ1",
        "colab_type": "text"
      },
      "source": [
        "* need to deal with loss\n",
        "* need to do optimisations (adjust weight over time based on the learning rate used)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6LL94miocty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e5f54a16-ea68-409f-9f32-edefbc4f16b2"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimiser = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# interate through the data and do that interation multiples time\n",
        "\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for data in trainset:\n",
        "    # data is a batch (10) of featuresets and labels\n",
        "    x, y = data\n",
        "    net.zero_grad()\n",
        "    output = net(x.view(-1, 28*28))\n",
        "    loss = F.nll_loss(output, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "  print(loss)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0439, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0195, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEMER1QZo6As",
        "colab_type": "text"
      },
      "source": [
        "```net.parameters()```\n",
        "* is everything that is adjustable in the model\n",
        "\n",
        "```lr```\n",
        "* the learning rate\n",
        "* sets the steps\n",
        "* most real problems decay the learning rate\n",
        "* we dont optimise for accucacy we optimise for loss (it just happens that accycacy follows loss) \n",
        "\n",
        "```EPOCH```\n",
        "* one full pass through the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBqet45_zWQS",
        "colab_type": "text"
      },
      "source": [
        "```net.zero_grad```\n",
        "* sets gradients to 0 before loss calc. You will do this likely every step.\n",
        "\n",
        "```F.nll_loss(output, y)```\n",
        "* calc and grab the loss value\n",
        "\n",
        "```loss.backward```\n",
        "* apply this loss backwards thru the network's parameters\n",
        "\n",
        "```optimizer.step()```\n",
        "* attempt to optimize weights to account for loss/gradients\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GydKa98puMLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da6dbb2b-0119-4ba5-ec64-d0f59c4fc875"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testset:\n",
        "    x, y = data\n",
        "    output = net(x.view(-1, 28*28))\n",
        "    for index, i in enumerate(output):\n",
        "      if torch.argmax(i) == y[index]:\n",
        "        correct += 1\n",
        "      total += 1\n",
        "\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMfZDxEGxbIx",
        "colab_type": "text"
      },
      "source": [
        "### Test NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQyBTHDxgJT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "0bb65ed9-81b3-4039-e84f-91ca8ab27c6d"
      },
      "source": [
        "# change sample to test recogistion \n",
        "sample = 1\n",
        "plt.imshow(x[sample].view(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADbRJREFUeJzt3X/sXfVdx/HXi/5CWsDWjVLaslZG\nq5UNsN8AydDMsBHALYU/QBqD1bCVREi2ZIsixgxj4sgi4OLmtIyuRSe/BoS6oMLqXMMGlW+bWqBM\nwNqN1v5gtLNFtv58+8f3dPlSvvdzb++vc8v7+Uhu7r3nfc73vHPTV8+953Pu/TgiBCCfk+puAEA9\nCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaTG93NnEz0pTtbkfu4SSOWn+j8diP1uZd2Owm/7\nCklflDRO0lcj4o7S+idrsi72ZZ3sEkDB2ljd8rptv+23PU7SlyVdKWmBpMW2F7T79wD0Vyef+S+S\n9GpEbI6IA5IekLSoO20B6LVOwj9T0mujnm+tlr2N7aW2h20PH9T+DnYHoJt6frY/IpZFxFBEDE3Q\npF7vDkCLOgn/NkmzRz2fVS0DcALoJPzPSTrX9lzbEyVdL2lVd9oC0GttD/VFxCHbt0j6F40M9S2P\niBe71hmAnuponD8inpD0RJd6AdBHXN4LJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4\ngaQIP5AU4QeSIvxAUh3N0mt7i6R9kg5LOhQRQ91oCkDvdRT+ym9ExI+68HcA9BFv+4GkOg1/SHrS\n9jrbS7vREID+6PRt/6URsc32GZKesv39iFgzeoXqP4WlknSyTulwdwC6paMjf0Rsq+53SXpM0kVj\nrLMsIoYiYmiCJnWyOwBd1Hb4bU+2ferRx5Iul/RCtxoD0FudvO2fLukx20f/zj9ExD93pSsAPdd2\n+CNis6Tzu9gL0Dfjpp9RXuHUycXyD79QPn91+v1TivUpD68t778PGOoDkiL8QFKEH0iK8ANJEX4g\nKcIPJNWNb/UB7Rm5RqRtb3zikmJ9zu+80rD22Zn/VNz2rPE/KdZnjisP9T1y3tRi/d6H5xbr/cCR\nH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSYpwfReNnzyrW/+fjZxfre+cdaVg7Y/7rxW3XfPChYv0k\nrSvWjygK25avMTiinyvWV+w9q1j//DevKdbP0TPFej9w5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiB\npBjnT+7gRxYW63d99UvF+i9NKM/C1NlYe2f+as+5DWtfW3FFcdtZ3/pxse4t24r1c35c/zh+Mxz5\ngaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCppuP8tpdL+pikXRFxXrVsmqQHJc2RtEXSdRGxp3dtom2X\nfLBYvuOevynWm43jj3OT40c0Hq1vtu37//GTxfq8r+0v7/vZjQ1LZ+l7xU07vcbgRNDKkX+FpGOv\niLhV0uqIOFfS6uo5gBNI0/BHxBpJu49ZvEjSyurxSklXd7kvAD3W7mf+6RGxvXq8Q9L0LvUDoE86\nPuEXESE1voDb9lLbw7aHD6rJZzQAfdNu+HfaniFJ1f2uRitGxLKIGIqIoQkqnzwC0D/thn+VpCXV\n4yWSHu9OOwD6pWn4bd8v6RlJ821vtX2jpDskfdT2K5I+Uj0HcAJpOs4fEYsblC7rci/ogV9b9u/F\n+sKJ44r1ef96Y7l+Z/vncd44//Riff4D64v12M85pE5whR+QFOEHkiL8QFKEH0iK8ANJEX4gKX66\n+11u1sRjv5P1dtsPv1WsNxvKO7Jh03H3dNTUDeV64x/9Rjdw5AeSIvxAUoQfSIrwA0kRfiApwg8k\nRfiBpBjnf5cb3je3WL/h1B3F+p4/P1Csn37VcbeEAcGRH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS\nYpz/Xe7bjy4s1tctfbpY/+75DxXrC/7s5mJ9zp88U6yjPhz5gaQIP5AU4QeSIvxAUoQfSIrwA0kR\nfiApR5R/Hd32ckkfk7QrIs6rlt0u6ZOSXq9Wuy0inmi2s9M8LS72u29m7/GzZxXrh17b2qdOjt+b\n115crP/bX/51sX7f3pnF+kO/d3nj4rMbi9vi+K2N1dobu93Kuq0c+VdIumKM5XdHxAXVrWnwAQyW\npuGPiDWSytO+ADjhdPKZ/xbbG20vtz21ax0B6It2w/8VSedIukDSdkl3NlrR9lLbw7aHD6o87xuA\n/mkr/BGxMyIOR8QRSfdIuqiw7rKIGIqIoQma1G6fALqsrfDbnjHq6TWSXuhOOwD6pelXem3fL+nD\nkt5je6ukz0n6sO0LNDKL8hZJN/WwRwA90DT8EbF4jMX39qCXgTbuV+Y3rH3um39f3Pa3nvz9Yn3e\nTc+11VM3THl4bbH+258qjNNLun/uU8X6386f3LA29dnipugxrvADkiL8QFKEH0iK8ANJEX4gKcIP\nJMVPd7doz/mNv76wcOK44rbfufLuYv3KP/qDYn3W579XrPfS5hXzyiv8aXmo7yfvbfztUr4QUi+O\n/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOP8LTpt81sNa+sOHC5uu3DiKcX6xlu+VKzPm17+SvCZ\n32388+un7DhQ3LaZD3yi/DstLx/8abF+9oM/bFg71FZH6BaO/EBShB9IivADSRF+ICnCDyRF+IGk\nCD+QFOP8LRq/rfFcpWvfen9x2wsnbu5o39+/9svF+knXNv7O/BGVp2Bf12QGtcMqz/Z8/d2fLdbP\nfK2+3yJAGUd+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iq6Ti/7dmS7pM0XVJIWhYRX7Q9TdKDkuZI\n2iLpuojY07tW63Xota0Na+v3nV3c9qSf/+9ut/M22w83/q2BZn65yZwDiy9fUqyfuYlx/BNVK0f+\nQ5I+ExELJF0i6WbbCyTdKml1RJwraXX1HMAJomn4I2J7RKyvHu+T9JKkmZIWSVpZrbZS0tW9ahJA\n9x3XZ37bcyRdKGmtpOkRsb0q7dDIxwIAJ4iWw297iqRHJH06IvaOrkVESGNfRG57qe1h28MH1eRC\ncgB901L4bU/QSPC/HhGPVot32p5R1WdI2jXWthGxLCKGImJogiZ1o2cAXdA0/LYt6V5JL0XEXaNK\nqyQdPRW8RNLj3W8PQK+08pXeD0m6QdLztjdUy26TdIekh2zfKOkHkq7rTYv9MX72rGK9NNQ3/I0P\nFLf9zatOa6unVv3v/pMb1vavOqO47ZnfeaNYP7zp5bZ6wuBrGv6IeFpq+KXuy7rbDoB+4Qo/ICnC\nDyRF+IGkCD+QFOEHkiL8QFIeuTK3P07ztLjYjA4CvbI2Vmtv7C7/3nqFIz+QFOEHkiL8QFKEH0iK\n8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9I\nivADSRF+ICnCDyTVNPy2Z9v+tu1Ntl+0/alq+e22t9neUN2u6n27ALplfAvrHJL0mYhYb/tUSets\nP1XV7o6Iv+hdewB6pWn4I2K7pO3V4322X5I0s9eNAeit4/rMb3uOpAslra0W3WJ7o+3ltqc22Gap\n7WHbwwe1v6NmAXRPy+G3PUXSI5I+HRF7JX1F0jmSLtDIO4M7x9ouIpZFxFBEDE3QpC60DKAbWgq/\n7QkaCf7XI+JRSYqInRFxOCKOSLpH0kW9axNAt7Vytt+S7pX0UkTcNWr5jFGrXSPphe63B6BXWjnb\n/yFJN0h63vaGatltkhbbvkBSSNoi6aaedAigJ1o52/+0pLHm+36i++0A6Beu8AOSIvxAUoQfSIrw\nA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyTliOjfzuzXJf1g1KL3SPpR3xo4\nPoPa26D2JdFbu7rZ2/si4r2trNjX8L9j5/ZwRAzV1kDBoPY2qH1J9NauunrjbT+QFOEHkqo7/Mtq\n3n/JoPY2qH1J9NauWnqr9TM/gPrUfeQHUJNawm/7Ctv/aftV27fW0UMjtrfYfr6aeXi45l6W295l\n+4VRy6bZfsr2K9X9mNOk1dTbQMzcXJhZutbXbtBmvO77237b4yS9LOmjkrZKek7S4ojY1NdGGrC9\nRdJQRNQ+Jmz71yW9Kem+iDivWvYFSbsj4o7qP86pEfGHA9Lb7ZLerHvm5mpCmRmjZ5aWdLWk31WN\nr12hr+tUw+tWx5H/IkmvRsTmiDgg6QFJi2roY+BFxBpJu49ZvEjSyurxSo384+m7Br0NhIjYHhHr\nq8f7JB2dWbrW167QVy3qCP9MSa+Ner5VgzXld0h60vY620vrbmYM06tp0yVph6TpdTYzhqYzN/fT\nMTNLD8xr186M193GCb93ujQiflXSlZJurt7eDqQY+cw2SMM1Lc3c3C9jzCz9M3W+du3OeN1tdYR/\nm6TZo57PqpYNhIjYVt3vkvSYBm/24Z1HJ0mt7nfV3M/PDNLMzWPNLK0BeO0GacbrOsL/nKRzbc+1\nPVHS9ZJW1dDHO9ieXJ2Ike3Jki7X4M0+vErSkurxEkmP19jL2wzKzM2NZpZWza/dwM14HRF9v0m6\nSiNn/P9L0h/X0UODvn5R0n9Utxfr7k3S/Rp5G3hQI+dGbpT0C5JWS3pF0rckTRug3v5O0vOSNmok\naDNq6u1Sjbyl3yhpQ3W7qu7XrtBXLa8bV/gBSXHCD0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxA\nUv8PdVsk6gdMFI4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNvq7hGyxvkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dcd84b1-e2d3-48a3-a2a1-c3d491db5e3a"
      },
      "source": [
        "print(torch.argmax(net(x[sample].view(-1,784))[0]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}